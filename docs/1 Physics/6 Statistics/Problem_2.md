# ğŸ“˜ Problem 2: Estimating Ï€ Using Monte Carlo Methods

## ğŸ¯ Motivation

Monte Carlo simulations are powerful numerical techniques that solve problems using randomness. A particularly elegant application is estimating the value of Ï€ using geometric probability.

In this project, we use two classical approaches to estimate Ï€:

* The Circle-based Monte Carlo method

* Buffonâ€™s Needle problem

These techniques highlight both the intuitive power of randomness and its practical application in solving mathematical problems.

### Part 1: Estimating Ï€ Using a Circle

#### ğŸ§  Theoretical Foundation

Imagine a *unit circle* (radius = 1) inscribed in a square of side length 2:

* Area of the circle

$$
ğ´_{circle}=ğœ‹ğ‘Ÿ^2=ğœ‹â‹…1^2=ğœ‹
$$

* The area of the square is:

$$
ğ´_{square}=(2)^2=4
$$

If we randomly generate 
ğ‘
 points inside the square and count how many of them fall inside the circle (
ğ‘€
), we get:



$$
\frac MN â‰ˆ \frac Ï€4 â‡’ Ï€ â‰ˆ 4â‹… \frac MN
$$

 

### ğŸ’» Simulation Code (Python)

 ```python
import numpy as np
import matplotlib.pyplot as plt

def estimate_pi_circle(n_points):
    x = np.random.uniform(-1, 1, n_points)
    y = np.random.uniform(-1, 1, n_points)
    inside = x**2 + y**2 <= 1
    pi_est = 4 * np.sum(inside) / n_points
    return pi_est, x, y, inside
```
### ğŸ“Š Visualization
```python
def plot_circle_points(x, y, inside):
    plt.figure(figsize=(6, 6))
    plt.scatter(x[inside], y[inside], s=1, color='blue', label='Inside Circle')
    plt.scatter(x[~inside], y[~inside], s=1, color='red', label='Outside Circle')
    plt.gca().set_aspect('equal')
    plt.title("Monte Carlo Circle Method for Ï€")
    plt.xlabel("x")
    plt.ylabel("y")
    plt.legend()
    plt.grid(True)
    plt.show()
 ```
### ğŸ“ˆ Convergence Analysis
```python
 
sample_sizes = [100, 500, 1000, 5000, 10000, 50000, 100000]
estimates = []

for n in sample_sizes:
    pi, *_ = estimate_pi_circle(n)
    estimates.append(pi)

plt.plot(sample_sizes, estimates, marker='o', label='Estimated Ï€')
plt.axhline(np.pi, color='green', linestyle='--', label='True Ï€')
plt.xscale('log')
plt.xlabel("Number of Points (log scale)")
plt.ylabel("Estimated Ï€")
plt.title("Convergence of Ï€ Estimate (Circle Method)")
 plt.legend()
 plt.grid(True)
 plt.show()
```

![alt text](image-4.png)

### ğŸ” Convergence Commentary
* âœ… Converges quickly and consistently.

* âœ… Even with a few thousand points, the estimate is close to the real value.

* âœ… Convergence rate: 
ğ‘‚
(
1
/
ğ‘›
)
O(1/ 
n
â€‹
 ), typical for Monte Carlo.

* âœ… Very computationally efficient.


## Part 2: Estimating Ï€ Using Buffonâ€™s Needle

### ğŸ§  Theoretical Foundation
Buffonâ€™s Needle is a probability problem involving dropping a needle of length 
ğ¿
 onto a plane with equally spaced parallel lines a distance 
ğ‘‘
 apart. The probability of crossing a line is:

$$
ğ‘ƒ=\frac {2ğ¿}{ğœ‹ğ‘‘} â‡’ ğœ‹â‰ˆ \frac {2ğ¿â‹…ğ‘}{ğ‘‘â‹…ğ¶}
$$
 
 
Where:

ğ‘
: number of needle drops

ğ¶
: number of crossings

**Constraint: 
ğ¿
â‰¤
ğ‘‘
Lâ‰¤d**

### ğŸ’» Simulation Code (Python)

```python
def estimate_pi_buffon(n_drops, L=1.0, d=2.0):
    x_center = np.random.uniform(0, d/2, n_drops)
    theta = np.random.uniform(0, np.pi/2, n_drops)
    crosses = x_center <= (L/2) * np.sin(theta)
    C = np.sum(crosses)
    if C == 0:
        return None, x_center, theta, crosses
    pi_est = (2 * L * n_drops) / (d * C)
    return pi_est, x_center, theta, crosses
```

### ğŸ“Š Visualization

```python
def plot_buffon_needles(x_center, theta, crosses, L=1.0, d=2.0):
    plt.figure(figsize=(8, 6))
    for i, (x, angle, cross) in enumerate(zip(x_center, theta, crosses)):
        x0 = x - (L/2) * np.cos(angle)
        x1 = x + (L/2) * np.cos(angle)
        y = i * 0.05
        color = 'blue' if cross else 'red'
        plt.plot([x0, x1], [y, y], color=color, linewidth=0.5)
    for i in range(5):
        plt.axvline(i * d, color='gray', linestyle='--')
    plt.title("Buffon's Needle Simulation")
    plt.xlabel("x")
    plt.ylabel("Needle Drops")
    plt.grid(True)
    plt.show()
```

### ğŸ“ˆ Convergence Analysis

```python
sample_sizes = [100, 500, 1000, 5000, 10000, 20000]
buffon_estimates = []

for n in sample_sizes:
    pi, *_ = estimate_pi_buffon(n)
    buffon_estimates.append(pi if pi else np.nan)

plt.plot(sample_sizes, buffon_estimates, marker='o', label="Estimated Ï€")
plt.axhline(np.pi, color='green', linestyle='--', label="True Ï€")
plt.xscale('log')
plt.xlabel("Number of Needles (log scale)")
plt.ylabel("Estimated Ï€")
plt.title("Convergence of Ï€ Estimate (Buffonâ€™s Needle)")
plt.legend()
plt.grid(True)
plt.show()
```

![alt text](image-5.png)

### ğŸ” Convergence Commentary

* âš ï¸ Converges more slowly and less consistently.

* âš ï¸ Sensitive to random outcomes; variance is higher.

* ğŸ” Better suited as a theoretical example of probability.

* âœ… Convergence rate is still 
$O(1/ \sqrt{n})$ but with higher variability.

## Summary & Comparison

| Method              | Estimate Accuracy | Convergence Rate       | Complexity | Notes                                 |
|---------------------|-------------------|-------------------------|------------|----------------------------------------|
| Circle Monte Carlo  | Good (fast)       | $O(1/\sqrt{n})$    | Low        | Easy to implement, fast convergence   |
| Buffonâ€™s Needle     | Slow convergence  | $O(1/\sqrt{n})$    | Medium     | More theoretical, needs careful setup |


## Colab

[click to go colab](https://colab.research.google.com/drive/1No0tWRqJLa2ODBW3PA3rwMwCgmtP2CQm?usp=sharing)